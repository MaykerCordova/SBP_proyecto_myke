â€‹ðŸ“‹ PROMPT MAESTRO: DetecciÃ³n de Fraude y ExtracciÃ³n de Reglas (Monitor Plus)
â€‹Rol: Eres un Senior Data Scientist especializado en PrevenciÃ³n de Fraude Bancario.
â€‹Contexto del Proyecto:
Trabajo en un banco y necesito detectar patrones de fraude complejos (especÃ­ficamente ataques de "Card Testing" donde prueban la tarjeta en Amazon y luego atacan en Google). El objetivo final NO es desplegar un modelo en tiempo real, sino extraer reglas de texto simples (IF/THEN) para implementarlas en un motor transaccional legacy llamado "Monitor Plus".
â€‹Datos y Fuente:
â€‹Base de Datos: Usaremos la tabla transaccional completa ("8750"), no la de alertas ("8850"), para evitar sesgos.
â€‹DefiniciÃ³n del Target:
â€‹1 (Fraude): Transacciones confirmadas como fraude ('F').
â€‹0 (No Fraude): Transacciones confirmadas buenas ('G') y normales ('N').
â€‹Excluir: Transacciones descartadas ('D') o pendientes para no introducir ruido.
â€‹Volumen: Alto desbalance de clases (muchas normales, pocos fraudes).
â€‹Estrategia TÃ©cnica (Model Distillation):
No usaremos un Ãrbol de DecisiÃ³n simple directamente sobre los datos porque es muy dÃ©bil. Usaremos una estrategia de "Maestro-Alumno":
â€‹IngenierÃ­a de Variables: Crearemos variables de ventana de tiempo para capturar secuencialidad (ej. tiene_transaccion_amazon_ultimos_30min, monto_promedio_usuario).
â€‹Modelo "Maestro" (Complex Learner): Entrenaremos un XGBoost o LightGBM robusto.
â€‹TÃ©cnica de Desbalance: Usaremos scale_pos_weight y un undersampling inteligente de la clase mayoritaria (manteniendo todos los falsos positivos 'G').
â€‹Output: Este modelo generarÃ¡ una probabilidad de fraude (score continuo) para cada transacciÃ³n.
â€‹Modelo "Alumno" (Surrogate Model): Entrenaremos un Decision Tree (CART) simple (profundidad limitada a 3-5 niveles).
â€‹Target del Alumno: AprenderÃ¡ a predecir la probabilidad (score) que generÃ³ el Maestro, NO la etiqueta binaria original. Esto permite capturar los matices y la "inteligencia" del XGBoost.
â€‹ExtracciÃ³n de Reglas: Usaremos export_text o skope-rules en Python para traducir las ramas del Ãrbol Alumno a reglas de negocio legibles (IF Monto > X AND Hora < Y...).
â€‹ValidaciÃ³n: Mediremos la "Fidelidad" (quÃ© tanto se parece la predicciÃ³n del Alumno a la del Maestro) antes de aprobar la regla.
â€‹Stack TecnolÃ³gico:
â€‹Lenguaje: Python.
â€‹LibrerÃ­as Clave: pandas (ETL), xgboost/lightgbm (Maestro), scikit-learn (Alumno), imbalanced-learn (Muestreo), pycaret (Benchmark inicial), plotnine (EDA).
